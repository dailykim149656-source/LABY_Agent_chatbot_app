# Azure Speech TTS êµ¬í˜„ ê°€ì´ë“œ

ì‘ì„±ì¼: 2026-01-31
ëŒ€ìƒ: LABY Agent Chatbot (chemical-sample-dashboard)
ë²”ìœ„: Text-to-Speech ê¸°ëŠ¥ êµ¬í˜„

---

## 1) ê°œìš”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TTS íë¦„                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  Chat API  â†’  ì‘ë‹µ í…ìŠ¤íŠ¸  â†’  Azure Speech SDK  â†’  ğŸ”Š   â”‚
â”‚                                                          â”‚
â”‚  [ì§ˆë¬¸]       [ë‹µë³€]          [TTS ë³€í™˜]        [ìŠ¤í”¼ì»¤] â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2) ì‚¬ì „ ì¤€ë¹„

### Azure Speech ë¦¬ì†ŒìŠ¤
- STTì™€ ë™ì¼í•œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ê°€ëŠ¥
- ë³„ë„ ì„¤ì • ë¶ˆí•„ìš”

### í™˜ê²½ë³€ìˆ˜ (STTì™€ ë™ì¼)
```env
# .env.local
NEXT_PUBLIC_AZURE_SPEECH_KEY=your-speech-key
NEXT_PUBLIC_AZURE_SPEECH_REGION=koreacentral
```

### SDK ì„¤ì¹˜ (STTì™€ ë™ì¼)
```bash
npm install microsoft-cognitiveservices-speech-sdk
```

---

## 3) íŒŒì¼ êµ¬ì¡°

```
chemical-sample-dashboard/
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ speech/
â”‚       â”œâ”€â”€ config.ts             # Azure Speech ì„¤ì • (ê³µìœ )
â”‚       â””â”€â”€ text-to-speech.ts     # TTS í´ë˜ìŠ¤
â”œâ”€â”€ hooks/
â”‚   â””â”€â”€ use-speech-synthesis.ts   # TTS React í›…
```

---

## 4) êµ¬í˜„ ì½”ë“œ

### A. TTS í´ë˜ìŠ¤ (`lib/speech/text-to-speech.ts`)

```typescript
import * as sdk from "microsoft-cognitiveservices-speech-sdk"
import { createSpeechConfig } from "./config"

export type TTSEventHandlers = {
  onStart?: () => void
  onEnd?: () => void
  onError?: (error: string) => void
}

// ì§€ì› ìŒì„± ëª©ë¡
export const VOICES = {
  "ko-KR": {
    female: "ko-KR-SunHiNeural",    // ì—¬ì„± (ê¸°ë³¸)
    male: "ko-KR-InJoonNeural",     // ë‚¨ì„±
  },
  "en-US": {
    female: "en-US-JennyNeural",
    male: "en-US-GuyNeural",
  },
  "ja-JP": {
    female: "ja-JP-NanamiNeural",
    male: "ja-JP-KeitaNeural",
  },
  "zh-CN": {
    female: "zh-CN-XiaoxiaoNeural",
    male: "zh-CN-YunxiNeural",
  },
} as const

export type VoiceLang = keyof typeof VOICES
export type VoiceGender = "female" | "male"

export class TextToSpeech {
  private synthesizer: sdk.SpeechSynthesizer | null = null
  private isSpeaking = false
  private lang: VoiceLang = "ko-KR"
  private gender: VoiceGender = "female"

  /**
   * ì–¸ì–´ ë° ì„±ë³„ ì„¤ì •
   */
  setVoice(lang: VoiceLang, gender: VoiceGender = "female"): void {
    this.lang = lang
    this.gender = gender
  }

  /**
   * í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¬ìƒ
   */
  async speak(text: string, handlers?: TTSEventHandlers): Promise<void> {
    if (this.isSpeaking) {
      this.stop()
    }

    return new Promise((resolve, reject) => {
      const speechConfig = createSpeechConfig()

      // ìŒì„± ì„¤ì •
      speechConfig.speechSynthesisLanguage = this.lang
      speechConfig.speechSynthesisVoiceName = VOICES[this.lang][this.gender]

      const audioConfig = sdk.AudioConfig.fromDefaultSpeakerOutput()
      this.synthesizer = new sdk.SpeechSynthesizer(speechConfig, audioConfig)

      this.isSpeaking = true
      handlers?.onStart?.()

      this.synthesizer.speakTextAsync(
        text,
        (result) => {
          this.isSpeaking = false
          handlers?.onEnd?.()

          if (result.reason === sdk.ResultReason.SynthesizingAudioCompleted) {
            resolve()
          } else {
            const error = `TTS ì‹¤íŒ¨: ${result.errorDetails}`
            handlers?.onError?.(error)
            reject(new Error(error))
          }

          this.cleanup()
        },
        (error) => {
          this.isSpeaking = false
          handlers?.onError?.(error)
          this.cleanup()
          reject(error)
        }
      )
    })
  }

  /**
   * SSMLë¡œ ì„¸ë°€í•œ ì œì–´ (ì†ë„, í”¼ì¹˜, ê°•ì¡° ë“±)
   */
  async speakSSML(ssml: string, handlers?: TTSEventHandlers): Promise<void> {
    if (this.isSpeaking) {
      this.stop()
    }

    return new Promise((resolve, reject) => {
      const speechConfig = createSpeechConfig()
      const audioConfig = sdk.AudioConfig.fromDefaultSpeakerOutput()
      this.synthesizer = new sdk.SpeechSynthesizer(speechConfig, audioConfig)

      this.isSpeaking = true
      handlers?.onStart?.()

      this.synthesizer.speakSsmlAsync(
        ssml,
        (result) => {
          this.isSpeaking = false
          handlers?.onEnd?.()

          if (result.reason === sdk.ResultReason.SynthesizingAudioCompleted) {
            resolve()
          } else {
            const error = `TTS ì‹¤íŒ¨: ${result.errorDetails}`
            handlers?.onError?.(error)
            reject(new Error(error))
          }

          this.cleanup()
        },
        (error) => {
          this.isSpeaking = false
          handlers?.onError?.(error)
          this.cleanup()
          reject(error)
        }
      )
    })
  }

  /**
   * ìŒì„± ì¬ìƒ ì¤‘ì§€
   */
  stop(): void {
    if (this.synthesizer) {
      this.synthesizer.close()
      this.synthesizer = null
      this.isSpeaking = false
    }
  }

  /**
   * ë¦¬ì†ŒìŠ¤ ì •ë¦¬
   */
  private cleanup(): void {
    if (this.synthesizer) {
      this.synthesizer.close()
      this.synthesizer = null
    }
  }

  /**
   * í˜„ì¬ ì¬ìƒ ì¤‘ì¸ì§€ í™•ì¸
   */
  get speaking(): boolean {
    return this.isSpeaking
  }
}
```

### B. React í›… (`hooks/use-speech-synthesis.ts`)

```typescript
"use client"

import { useState, useCallback, useRef, useEffect } from "react"
import { TextToSpeech, VoiceLang, VoiceGender } from "@/lib/speech/text-to-speech"

export function useSpeechSynthesis() {
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const ttsRef = useRef<TextToSpeech | null>(null)

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ TTS ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
  useEffect(() => {
    ttsRef.current = new TextToSpeech()
    return () => {
      ttsRef.current?.stop()
    }
  }, [])

  /**
   * í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ì¬ìƒ
   */
  const speak = useCallback(async (text: string) => {
    setError(null)
    try {
      await ttsRef.current?.speak(text, {
        onStart: () => setIsSpeaking(true),
        onEnd: () => setIsSpeaking(false),
        onError: (err) => setError(err),
      })
    } catch (err) {
      setError(err instanceof Error ? err.message : "TTS ì‹¤íŒ¨")
    }
  }, [])

  /**
   * SSMLë¡œ ì¬ìƒ
   */
  const speakSSML = useCallback(async (ssml: string) => {
    setError(null)
    try {
      await ttsRef.current?.speakSSML(ssml, {
        onStart: () => setIsSpeaking(true),
        onEnd: () => setIsSpeaking(false),
        onError: (err) => setError(err),
      })
    } catch (err) {
      setError(err instanceof Error ? err.message : "TTS ì‹¤íŒ¨")
    }
  }, [])

  /**
   * ìŒì„± ì„¤ì • ë³€ê²½
   */
  const setVoice = useCallback((lang: VoiceLang, gender: VoiceGender = "female") => {
    ttsRef.current?.setVoice(lang, gender)
  }, [])

  /**
   * ì¬ìƒ ì¤‘ì§€
   */
  const stop = useCallback(() => {
    ttsRef.current?.stop()
    setIsSpeaking(false)
  }, [])

  return {
    isSpeaking,
    error,
    speak,
    speakSSML,
    setVoice,
    stop,
  }
}
```

---

## 5) ì‚¬ìš© ì˜ˆì‹œ

### ê¸°ë³¸ ì‚¬ìš©

```typescript
"use client"

import { useSpeechSynthesis } from "@/hooks/use-speech-synthesis"
import { Volume2, VolumeX } from "lucide-react"
import { Button } from "@/components/ui/button"

export function SpeakButton({ text }: { text: string }) {
  const { isSpeaking, speak, stop } = useSpeechSynthesis()

  const handleClick = () => {
    if (isSpeaking) {
      stop()
    } else {
      speak(text)
    }
  }

  return (
    <Button variant="ghost" size="icon" onClick={handleClick}>
      {isSpeaking ? (
        <Volume2 className="size-5 animate-pulse text-blue-500" />
      ) : (
        <VolumeX className="size-5" />
      )}
    </Button>
  )
}
```

### Chat ì‘ë‹µ ì½ê¸°

```typescript
"use client"

import { useSpeechSynthesis } from "@/hooks/use-speech-synthesis"
import { postChatMessage } from "@/lib/data/chat"

export function VoiceChat({ roomId }: { roomId: string }) {
  const { speak, isSpeaking } = useSpeechSynthesis()

  const sendAndSpeak = async (message: string) => {
    // 1. ì±—ë´‡ API í˜¸ì¶œ
    const response = await postChatMessage(roomId, {
      message,
      sender_type: "guest",
    })

    // 2. ì‘ë‹µì„ ìŒì„±ìœ¼ë¡œ ì¶œë ¥
    await speak(response.assistantMessage.content)
  }

  return (
    <div>
      <button onClick={() => sendAndSpeak("ì˜¤ëŠ˜ ì‹¤í—˜ ì¼ì • ì•Œë ¤ì¤˜")}>
        ì§ˆë¬¸í•˜ê¸°
      </button>
      {isSpeaking && <span>ğŸ”Š ì½ëŠ” ì¤‘...</span>}
    </div>
  )
}
```

### ì–¸ì–´ë³„ ìŒì„± ë³€ê²½

```typescript
const { speak, setVoice } = useSpeechSynthesis()

// í•œêµ­ì–´ ì—¬ì„± ìŒì„± (ê¸°ë³¸)
setVoice("ko-KR", "female")
await speak("ì•ˆë…•í•˜ì„¸ìš”")

// ì˜ì–´ ë‚¨ì„± ìŒì„±
setVoice("en-US", "male")
await speak("Hello, how can I help you?")

// ì¼ë³¸ì–´ ì—¬ì„± ìŒì„±
setVoice("ja-JP", "female")
await speak("ã“ã‚“ã«ã¡ã¯")
```

---

## 6) SSML í™œìš©

SSML(Speech Synthesis Markup Language)ë¡œ ì„¸ë°€í•œ ì œì–´ ê°€ëŠ¥:

### ì†ë„/í”¼ì¹˜ ì¡°ì ˆ

```typescript
const { speakSSML } = useSpeechSynthesis()

const ssml = `
<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="ko-KR">
  <voice name="ko-KR-SunHiNeural">
    <prosody rate="slow" pitch="high">
      ì²œì²œíˆ, ë†’ì€ í†¤ìœ¼ë¡œ ë§í•©ë‹ˆë‹¤.
    </prosody>
  </voice>
</speak>
`

await speakSSML(ssml)
```

### ê°•ì¡°/ì¼ì‹œì •ì§€

```typescript
const ssml = `
<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="ko-KR">
  <voice name="ko-KR-SunHiNeural">
    <emphasis level="strong">ê²½ê³ !</emphasis>
    <break time="500ms"/>
    ë„˜ì–´ì§ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.
  </voice>
</speak>
`
```

### ê°ì • í‘œí˜„ (Neural ìŒì„±)

```typescript
const ssml = `
<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="ko-KR">
  <voice name="ko-KR-SunHiNeural">
    <mstts:express-as style="cheerful" xmlns:mstts="https://www.w3.org/2001/mstts">
      ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?
    </mstts:express-as>
  </voice>
</speak>
`
```

---

## 7) ì§€ì› ìŒì„± ëª©ë¡

### í•œêµ­ì–´ (ko-KR)

| ìŒì„± ì´ë¦„ | ì„±ë³„ | ìŠ¤íƒ€ì¼ |
|----------|------|--------|
| ko-KR-SunHiNeural | ì—¬ì„± | ì¼ë°˜ |
| ko-KR-InJoonNeural | ë‚¨ì„± | ì¼ë°˜ |
| ko-KR-HyunsuNeural | ë‚¨ì„± | ì¼ë°˜ |
| ko-KR-BongJinNeural | ë‚¨ì„± | ì¼ë°˜ |
| ko-KR-GookMinNeural | ë‚¨ì„± | ì¼ë°˜ |
| ko-KR-JiMinNeural | ì—¬ì„± | ì¼ë°˜ |
| ko-KR-SeoHyeonNeural | ì—¬ì„± | ì¼ë°˜ |
| ko-KR-SoonBokNeural | ì—¬ì„± | ì¼ë°˜ |
| ko-KR-YuJinNeural | ì—¬ì„± | ì¼ë°˜ |

### ì˜ì–´ (en-US)

| ìŒì„± ì´ë¦„ | ì„±ë³„ | ìŠ¤íƒ€ì¼ |
|----------|------|--------|
| en-US-JennyNeural | ì—¬ì„± | ë‹¤ì–‘í•œ ê°ì • ì§€ì› |
| en-US-GuyNeural | ë‚¨ì„± | ì¼ë°˜ |
| en-US-AriaNeural | ì—¬ì„± | ë‰´ìŠ¤ìºìŠ¤í„° ìŠ¤íƒ€ì¼ |

---

## 8) ì˜ˆìƒ ë¹„ìš©

| í•­ëª© | ë¬´ë£Œ ê³„ì¸µ (F0) | ìœ ë£Œ ê³„ì¸µ (S0) |
|------|---------------|---------------|
| Neural TTS | 50ë§Œ ë¬¸ì/ì›” | $16/1M ë¬¸ì |
| Standard TTS | 500ë§Œ ë¬¸ì/ì›” | $4/1M ë¬¸ì |

**ê¶Œì¥:** Neural ìŒì„±ì´ í’ˆì§ˆì´ ì¢‹ìœ¼ë¯€ë¡œ Neural ì‚¬ìš© ê¶Œì¥

---

## 9) ë¬¸ì œ í•´ê²°

### ì†Œë¦¬ê°€ ì•ˆ ë“¤ë¦¼
- ë¸Œë¼ìš°ì € ë³¼ë¥¨ í™•ì¸
- ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ì¶œë ¥ ì¥ì¹˜ í™•ì¸
- `AudioConfig.fromDefaultSpeakerOutput()` í™•ì¸

### ìŒì„±ì´ ëŠê¹€
- ë„¤íŠ¸ì›Œí¬ ìƒíƒœ í™•ì¸
- í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ë¶„í•  ì²˜ë¦¬

### SSML ì˜¤ë¥˜
```
Error: SSML is invalid
```
- XML ë¬¸ë²• í™•ì¸
- `xmlns` ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í™•ì¸
- ìŒì„± ì´ë¦„ ì˜¤íƒ€ í™•ì¸

---

## 10) ë‹¤ìŒ ë‹¨ê³„

- [ ] ì‚¬ê³  ì•Œë¦¼ TTS ì—°ë™
- [ ] Wake Word êµ¬í˜„ ("Hey LABY")
- [ ] ìŒì„± ëŒ€í™” UI í†µí•©
